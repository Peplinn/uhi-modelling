{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d481fc1e",
   "metadata": {},
   "source": [
    "# Workflow for the entire project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55690a03",
   "metadata": {},
   "source": [
    "> ## \"What's this?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a530eefa",
   "metadata": {},
   "source": [
    "Before I write any code, I want to make sure that I have a detailed plan to follow and a clear goal at each stage.\n",
    "\n",
    "This project is concerned with predicting the intensity of the Urban Heat Island effect (the temperature essentially) in places where there is inadequate monitoring technology.\n",
    "\n",
    "This will be done by analysing the environmental variables that ARE available and using them as predictors for UHIs (Urban Heat Island Intensity)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7f454c",
   "metadata": {},
   "source": [
    "> ## \"But what is an Urban Heat Island?\"\n",
    "\n",
    "Well, I'm glad you asked!\n",
    "\n",
    "A **UHI** is a place where the kinds of structures present make it difficult for heat to dissipate easily, and days and (especially?) nights are significantly warmer as a result.\n",
    "\n",
    "The two biggest culprits for this effect are:  \n",
    "1. Close building proximities (because buildings today just loooove to retain heat)\n",
    "2. The lack of vegetation (commonly referred to as green cover) to either shield from or distribute (I don't know how yet) the heat."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6775aff3",
   "metadata": {},
   "source": [
    "> ## \"Okay, I get that. But why does this matter?\"\n",
    "\n",
    "You are very curious Padawan.\n",
    "\n",
    "It is often the case that cities build first and think about liveability later. Well, this is certainly the case in Lagos.  \n",
    "Nigeria's (Africa for the hopeful) largest economy with a population that overwhelms infrastructure.\n",
    "\n",
    "In this city, green spaces are a luxury and builders are constantly trying to fit the most people in the smallest possible spaces.  \n",
    "Human rights concerns aside, this makes it very difficult for a city perfectly in the tropics to manage the inevitable buildup of heat.\n",
    "\n",
    "The nail in this coffin is the absence of any kind of monitoring technology. This means that many people probably die unnoticed in the warmer months.  \n",
    "This doesn't have to be the case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b69dab",
   "metadata": {},
   "source": [
    "> ## \"Oof. So how do we start modelling?\"\n",
    "\n",
    "Good question. The first thing any statistician needs (after identifying a problem) is data.\n",
    "\n",
    "What data do we need? What are the variables we're examining?\n",
    "\n",
    "We've mentioned building proximity and vegetation (green cover). To help us find more, we can look at related studies.\n",
    "\n",
    "What did THEY examine?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e438228",
   "metadata": {},
   "source": [
    "### 1. Ana Oliveira et al.\n",
    "**Method**: Random Forest\n",
    "\n",
    "#### **Response**\n",
    "Nocturnal Landsat LST\n",
    "\n",
    "#### **Predictors**\n",
    "1. lat\n",
    "2. long\n",
    "3. alt\n",
    "4. nocturnal lst\n",
    "5. diurnal ndvi\n",
    "6. diurnal latent heat flux\n",
    "7. diurnal sensible heat flux\n",
    "8. diurnal storage heat flux\n",
    "\n",
    "### 2. Andreas Wicki et al.\n",
    "**Method**: Multiple Linear Regression\n",
    "\n",
    "#### **Response**\n",
    "Nocturnal Air Temperature\n",
    "\n",
    "#### **Predictors**\n",
    "1. Landsat Data (LST, NDVI, and Albedo)\n",
    "2. Urban Morphology, which is the 3D arrangement and density of buildings and vegetation\n",
    "3. Land Cover (Building to Surface Fraction, Impervious Surface Fraction, and Pervious Surface Fraction)\n",
    "\n",
    "### 3. Shun Fu et al.\n",
    "**Method**: CNN\n",
    "\n",
    "#### **Response**\n",
    "LST\n",
    "\n",
    "#### **Predictors**\n",
    "Spectral/Land Cover Indices:\n",
    "   1. NDVI (Normalized Difference Vegetation Index)\n",
    "   2. NDBI (Normalized Difference Built-up Index)\n",
    "   3. MNDWI (Modified Normalized Difference Water Index)\n",
    "   4. SAVI (Soil Adjusted Vegetation Index)\n",
    "\n",
    "### 4. Alireza Attarhay Tehrani et al.\n",
    "**Method**: Artificial Neural Network, Deep Neural Network, Gates Reccurent Unit\n",
    "\n",
    "#### **Response**\n",
    "UHI Intensity - Measured as difference in temperature between urban and rural areas.\n",
    "\n",
    "#### **Predictors**\n",
    "1. Topological & Spatial Features\n",
    "   1. Geographical Location of Urban Areas\n",
    "   2. Azimuth Angle (Building Orientation Relative to the Sun)\n",
    "2. Urban Form Metrics\n",
    "   1. Building Density (% of land covered by buildings)\n",
    "   2. Average Building Height\n",
    "   3. Average Building Volume\n",
    "   4. Facade-to-Site Ratio (Ratio of Building Surface Area to Plot Area)\n",
    "3. Land Use & Green Infrastructure:\n",
    "   1. Green Space Ratio (% of vegetation cover)\n",
    "   2. Occupied Area (space covered by buildings)\n",
    "   3. Unoccupied Area (open/vacant land)\n",
    "4. Climatic Data (from UWG):\n",
    "   1. Dry-bulb temperature (from Typical Meteorological Year 3 (TMY3))\n",
    "   2. Humidity, wind patterns (indirectly considered via UWG simulations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48611c6a",
   "metadata": {},
   "source": [
    "> ## \"So, what did you find?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e86ba02",
   "metadata": {},
   "source": [
    "In these four works, we can see the following commonalities:\n",
    "\n",
    "**Response: Urban Heat Island Intensity**  \n",
    "This is measured as:  \n",
    "- Noctural Landsat Land Surface Temperature\n",
    "- Nocturnal Air Temperature\n",
    "- Temperature difference between urban areas and rural surroundings\n",
    "\n",
    "**Predictors:**\n",
    "1. Geographical Location\n",
    "2. Nocturnal Land Surface Temperature\n",
    "3. Normalized Difference Vegetative Index (Land Cover)  \n",
    "   Measures vegetation health and density.  \n",
    "   **Near-Infrared (NIR)** – High reflectance from healthy plants.  \n",
    "   **Red** – Absorbed by chlorophyll.\n",
    "   $$\n",
    "     NDVI = \\frac{NIR - Red}{NIR + Red}\n",
    "   $$\n",
    "   - High NDVI (0.6–1.0): Dense vegetation (forests, crops).  \n",
    "   - Low NDVI (0–0.2): Urban areas, bare soil, water.  \n",
    "   - Negative NDVI: Water bodies.  \n",
    "4. Normalized Difference Built-up Index (Land Cover)  \n",
    "   **Short-Wave Infrared (SWIR)** – High reflectance from impervious surfaces.  \n",
    "   **Near-Infrared (NIR)** – Low reflectance from built-up areas.\n",
    "   $$\n",
    "     NDBI = \\frac{SWIR - NIR}{SWIR + WIR}\n",
    "   $$\n",
    "   - High NDBI (>0): Urbanized regions (concrete, asphalt).  \n",
    "   - Low/Negative NDBI: Vegetation or water.  \n",
    "5. Modified Normalized Difference Water Index (Land Cover)  \n",
    "   **Green** – High reflectance from water.  \n",
    "   **Short-Wave Infrared (SWIR)** – Low reflectance from water.  \n",
    "   $$\n",
    "     MNDWI = \\frac{Green - SWIR}{Green + SWIR}\n",
    "   $$\n",
    "   - High MNDWI (>0.2): Water bodies (lakes, rivers).  \n",
    "   - Low MNDWI (<0): Urban/vegetated areas.  \n",
    "6. Soil Adjusted Vegetation Index (Land Cover)\n",
    "7. Albedo\n",
    "8. Building Density\n",
    "9. Altitide (Elevation)\n",
    "10. Vegetation Density (Land Cover)\n",
    "11.  Green Space Ratio (Land Cover)\n",
    "12.  Humidity\n",
    "13.  Building Orientation Relative to the Sun (Azimuth Angle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac1d991",
   "metadata": {},
   "source": [
    "> ## \"That's... a lot of features\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1646adcf",
   "metadata": {},
   "source": [
    "Right on.\n",
    "\n",
    "After I select the model I'm going to use for this, I will perform **feature reduction** (using, say, Principal Component Analysis) and use the optimal number of features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335512d7",
   "metadata": {},
   "source": [
    "> ## \"So what now?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75157eb8",
   "metadata": {},
   "source": [
    "We find our data.\n",
    "\n",
    "From my discussion with GPT, I have been able to understand the following.\n",
    "\n",
    "|Feature|Purpose|\n",
    "|---|---|\n",
    "|NDVI|Measures vegetation density|\n",
    "|NDBI|Measures built-up urban areas|\n",
    "|MNDWI|Identifies water bodies|\n",
    "|SAVI|Like NDVI, but corrects for soil effects|\n",
    "|Albedo|Reflectivity of surfaces, which affects heat absorption|\n",
    "|Elevation|Higher altitudes are generally cooler|\n",
    "|Land Cover Class|Helps distinguish urban, vegetation, water, etc.|\n",
    "\n",
    "\n",
    "## Data Collection\n",
    "\n",
    "The first thing we do is collect our Landsat images from Google Earth Engine. This is done in the code below:\n",
    "\n",
    "```python\n",
    "collection = (\n",
    "    ee.ImageCollection(\"LANDSAT/LC08/C02/T1_L2\")\n",
    "    .filterBounds(lagos_aoi)\n",
    "    .filterDate(\"2021-11-01\", \"2024-03-31\")\n",
    "    .filterMetadata(\"CLOUD_COVER\", \"less_than\", 20)\n",
    ")\n",
    "```\n",
    "\n",
    "What this does is select the images from 2021 to 2024 within the Lagos boundary I defined, and with adequately small cloud cover (so I can actually see the ground).\n",
    "\n",
    "### Image Bands\n",
    "\n",
    "Now, because each of the landsat images actually has several bands (e.g., Infrared, RED, NIR, SWIR, etc., sort of the way images store R, G and B values), this code:\n",
    "\n",
    "```python\n",
    "image = collection.median().clip(lagos_aoi)\n",
    "```\n",
    "\n",
    "It goes to a pixel and, within each band (like Red), calculates the median value across that entire date range (2021 - 2024). Essentially, it is crunching all the potential values within that date range into a single representative figure.\n",
    "\n",
    "> \"Why the hell are we doing this?\"\n",
    "\n",
    "Well, some of the final spectral indices we want, like NDVI, actually rely on these values. Remember that NDVI is:\n",
    "\n",
    "$$\n",
    "\tNDVI = \\frac{NIR - Red}{NIR + Red}\n",
    "$$\n",
    "\n",
    "That median **red** we calculate at that point is what we use in this formula to calculate the NDVI at that point.\n",
    "\n",
    "From the immediate code above, we only perform that calculation for the Lagos boundary.\n",
    "\n",
    "---\n",
    "\n",
    "**Comment:**\n",
    "The NDVI formula above measures how much near infrared light a surface reflects and how much red light it absorbs to determine whether it is a plant or not, and how healthy it is.\n",
    "\n",
    "- Healthy plants: Closer to 1\n",
    "- Bare Soil: Closer to 0\n",
    "- Water and Non-plant surfaces: Closer to -1\n",
    "\n",
    "## Calculating Spectral Indices\n",
    "\n",
    "The lines below calculate the rest of the spectral indices and add them — with the ndvi band already calculated — into the **features** image.\n",
    "\n",
    "```python\n",
    "ndbi = image.normalizedDifference([\"SR_B6\", \"SR_B5\"]).rename(\"NDBI\")\n",
    "\n",
    "mndwi = image.normalizedDifference([\"SR_B3\", \"SR_B6\"]).rename(\"MNDWI\")\n",
    "\n",
    "savi = image.expression(\n",
    "    \"((NIR - RED) / (NIR + RED + L)) * (1 + L)\",\n",
    "    {\n",
    "        \"NIR\": image.select(\"SR_B5\"),\n",
    "        \"RED\": image.select(\"SR_B4\"),\n",
    "        \"L\": 0.5,  # soil brightness correction factor\n",
    "    },\n",
    ").rename(\"SAVI\")\n",
    "\n",
    "albedo = image.expression(\n",
    "    \"0.356 * B2 + 0.130 * B4 + 0.373 * B5 + 0.085 * B6 + 0.072 * B7 - 0.0018\",\n",
    "    {\n",
    "        \"B2\": image.select(\"SR_B2\"),  # Blue\n",
    "        \"B4\": image.select(\"SR_B4\"),  # Red\n",
    "        \"B5\": image.select(\"SR_B5\"),  # NIR\n",
    "        \"B6\": image.select(\"SR_B6\"),  # SWIR1\n",
    "        \"B7\": image.select(\"SR_B7\"),  # SWIR2\n",
    "    },\n",
    ").rename(\"Albedo\")\n",
    "\n",
    "elevation = ee.Image(\"USGS/SRTMGL1_003\").clip(lagos_aoi).rename(\"Elevation\")\n",
    "\n",
    "landcover = ee.Image(\"ESA/WorldCover/v100/2020\").clip(lagos_aoi).rename(\"LandCover\")\n",
    "\n",
    "features = ndvi.addBands([ndbi, mndwi, savi, albedo, lst, elevation, landcover])\n",
    "```\n",
    "\n",
    "## Sampling from Feature Image\n",
    "\n",
    "We could probably use all the data in our analysis, but depending on the resolution of the image, that could be hundreds of thousands to millions of rows of data. 500 should be enough, and we sample that many points in the line below:\n",
    "\n",
    "```python\n",
    "points = features.sample(region=lagos_aoi, scale=30, numPixels=500, geometries=True)\n",
    "```\n",
    "\n",
    "We export those points to CSV in the line below using `geemap` and continue the rest of our analysis with pandas.\n",
    "\n",
    "```python\n",
    "geemap.ee_to_csv(points, filename=\"resources/data/UHI_features.csv\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7808ea01",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "penv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
